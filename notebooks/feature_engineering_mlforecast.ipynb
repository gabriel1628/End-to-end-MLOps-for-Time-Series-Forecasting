{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this notebook we will select and create features to feed our ML model. For now, we will focus on the consumption data.\n",
    "<br>\n",
    "We will use `MLForecast` to create the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/preprocessed/consumption_train.csv\", parse_dates=[\"datetime\"])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series\")\n",
    "from utils import load_config\n",
    "config = load_config(\"../config/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"n_lag_transforms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = config[\"forecast_horizon\"]\n",
    "n_lags = config[\"n_lags\"]\n",
    "rolling_mean_window_size = config[\"rolling_mean_window_size\"]\n",
    "n_lag_transforms = n_lags\n",
    "date_features = config[\"date_features\"]\n",
    "\n",
    "def feature_engineering(\n",
    "    df,\n",
    "    id_col=\"prediction_unit_id\",\n",
    "    time_col=\"datetime\",\n",
    "    target_col=\"target\",\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    n_lags=n_lags,\n",
    "    rolling_mean_window_size=rolling_mean_window_size,\n",
    "    date_features=date_features,\n",
    "    on_test=False, # if True, stack last rows of train on top of test data\n",
    "):\n",
    "    fcst = MLForecast(\n",
    "        models=[],\n",
    "        freq=\"h\",\n",
    "        lags=[i for i in range(forecast_horizon, forecast_horizon + n_lags)],\n",
    "        lag_transforms={\n",
    "            i: [ExpandingMean(), RollingMean(window_size=rolling_mean_window_size)]\n",
    "            for i in range(forecast_horizon, forecast_horizon + n_lag_transforms)\n",
    "        },\n",
    "        date_features=date_features,\n",
    "    )\n",
    "    id_columns = [id_col, time_col, target_col]\n",
    "    return fcst.preprocess(df[id_columns], id_col=id_col, time_col=time_col, target_col=target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 2\n",
    "n_lags = 3\n",
    "rolling_mean_window_size = 2\n",
    "n_lag_transforms = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_engineering(df)\n",
    "X[X[\"prediction_unit_id\"] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"prediction_unit_id\"] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(df_processed.head())\n",
    "except:\n",
    "    df_processed = pd.read_csv(\"../data/processed/consumption_train_processed.csv\")\n",
    "    display(df_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X.sort_values(by=[\"prediction_unit_id\", \"datetime\"])\n",
    "df_ = df.sort_values(by=[\"prediction_unit_id\", \"datetime\"])\n",
    "df_.head()\n",
    "# TODO: determine the value of `step` for which `X` and `df` are aligned according to \"datetime\".\n",
    "# Once it's done, stack the last `n_step` values of `train` on top of `test` so that we don't lose\n",
    "# the first rows of test after preprocessing.\n",
    "step = forecast_horizon + max(n_lags, n_lag_transforms) - 1\n",
    "(X_[\"datetime\"].head() == df_[\"datetime\"].iloc[step:step+5]).sum() == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack last train rows on top of test\n",
    "\n",
    "When applying feature engineering we remove the first rows of the dataframe.\n",
    "First determine the value of `step` for which `X` and `df` are aligned according to \"datetime\".\n",
    "Once it's done, stack the last `n_step` values of `train` on top of `test` so that we don't lose\n",
    "the first rows of test after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "forecast_horizon_list = random.choices(range(1, 10), k=3)\n",
    "n_lags_list = random.choices(range(1, 10), k=3)\n",
    "rolling_mean_window_size_list = random.choices(range(1, 10), k=3)\n",
    "n_lag_transforms_list = random.choices(range(1, 10), k=3)\n",
    "forecast_horizon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "x = [1, 2, 3]\n",
    "y = ['a', 'b', 'c']\n",
    "combinations = itertools.product(forecast_horizon_list, n_lags_list, rolling_mean_window_size_list, n_lag_transforms_list)\n",
    "# len(list(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"forecast_horizon_list : {forecast_horizon_list}\")\n",
    "# print(f\"n_lags_list : {n_lags_list}\")\n",
    "# print(f\"rolling_mean_window_size_list : {rolling_mean_window_size_list}\")\n",
    "# print(f\"n_lag_transforms_list : {n_lag_transforms_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in combinations:\n",
    "#     print(_)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in combinations:\n",
    "    forecast_horizon, n_lags, rolling_mean_window_size, n_lag_transforms = _\n",
    "    print(_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_[\"datetime\"].tail() == df_[\"datetime\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X.sort_values(by=[\"prediction_unit_id\", \"datetime\"])\n",
    "X_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.sort_values(by=[\"prediction_unit_id\", \"datetime\"])\n",
    "df_.head()\n",
    "step = forecast_horizon + max(n_lags, n_lag_transforms) - 1\n",
    "df_.iloc[step:step+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grouped = X.groupby(by=\"prediction_unit_id\").tail()\n",
    "X_grouped[X_grouped[\"prediction_unit_id\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(by=\"prediction_unit_id\").tail()\n",
    "grouped[grouped[\"prediction_unit_id\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the function on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_engineering(df, inference=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = df[df[\"prediction_unit_id\"]==0].iloc[-24:]\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.reset_index(drop=True, inplace=True)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_engineering(ts, inference=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
