{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import mlflow\n",
    "import optuna\n",
    "import os\n",
    "import sys\n",
    "from utils import train_test_split\n",
    "from preprocessing.preprocessing import *\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 48\n",
    "n_lags = 48\n",
    "model_name = \"lightgbm\"\n",
    "preprocessing_version = 2\n",
    "config_version = 1\n",
    "config_dir_path = \"./configuration_files\"\n",
    "study_path = \"./optuna_studies\"\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast_horizon = 24\n",
    "# n_lags = 48\n",
    "# test_window = 24*60 # in hours\n",
    "# preprocessing_version = 1 # preprocessing version\n",
    "# study_version = 1 # Optuna study to take hyperparameters from\n",
    "# random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>96.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>17.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>2</td>\n",
       "      <td>656.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>59.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>4</td>\n",
       "      <td>501.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    datetime  prediction_unit_id  consumption\n",
       "0 2021-09-01                   0       96.590\n",
       "1 2021-09-01                   1       17.314\n",
       "2 2021-09-01                   2      656.859\n",
       "3 2021-09-01                   3       59.000\n",
       "4 2021-09-01                   4      501.760"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/consumption.csv\")\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009176, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the last 60 days of each unit for test\n",
    "df_train, df_test = train_test_split(df, test_window=24 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.shape[0] == df_train.shape[0] + df_test.shape[0]\n",
    "assert df.shape[1] == df_train.shape[1] == df_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set : 9.85% of the data set\n"
     ]
    }
   ],
   "source": [
    "test_size = df_test.shape[0] / (df.shape[0])\n",
    "print(f\"test set : {round(test_size*100, 2)}% of the data set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessing version 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using preprocessing version {preprocessing_version}\")\n",
    "preprocessing = vars()[f\"preprocessing_{preprocessing_version}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/mlforecast/core.py:455: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feat_name] = feat_vals[restore_idxs]\n",
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/mlforecast/core.py:455: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feat_name] = feat_vals[restore_idxs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (854079, 99)\n",
      "y_train shape : (854079,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag48</th>\n",
       "      <th>lag49</th>\n",
       "      <th>lag50</th>\n",
       "      <th>lag51</th>\n",
       "      <th>lag52</th>\n",
       "      <th>lag53</th>\n",
       "      <th>lag54</th>\n",
       "      <th>lag55</th>\n",
       "      <th>lag56</th>\n",
       "      <th>lag57</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_lag68_window_size24</th>\n",
       "      <th>expanding_mean_lag69</th>\n",
       "      <th>rolling_mean_lag69_window_size24</th>\n",
       "      <th>expanding_mean_lag70</th>\n",
       "      <th>rolling_mean_lag70_window_size24</th>\n",
       "      <th>expanding_mean_lag71</th>\n",
       "      <th>rolling_mean_lag71_window_size24</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>120.540</td>\n",
       "      <td>134.986</td>\n",
       "      <td>150.412</td>\n",
       "      <td>152.763</td>\n",
       "      <td>136.130</td>\n",
       "      <td>121.033</td>\n",
       "      <td>80.621</td>\n",
       "      <td>43.428</td>\n",
       "      <td>46.840</td>\n",
       "      <td>43.671</td>\n",
       "      <td>...</td>\n",
       "      <td>82.505417</td>\n",
       "      <td>82.612111</td>\n",
       "      <td>81.860500</td>\n",
       "      <td>81.756654</td>\n",
       "      <td>81.308000</td>\n",
       "      <td>81.145600</td>\n",
       "      <td>80.502083</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>107.129</td>\n",
       "      <td>120.540</td>\n",
       "      <td>134.986</td>\n",
       "      <td>150.412</td>\n",
       "      <td>152.763</td>\n",
       "      <td>136.130</td>\n",
       "      <td>121.033</td>\n",
       "      <td>80.621</td>\n",
       "      <td>43.428</td>\n",
       "      <td>46.840</td>\n",
       "      <td>...</td>\n",
       "      <td>83.241833</td>\n",
       "      <td>83.355714</td>\n",
       "      <td>82.505417</td>\n",
       "      <td>82.612111</td>\n",
       "      <td>81.860500</td>\n",
       "      <td>81.756654</td>\n",
       "      <td>81.308000</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>81.920</td>\n",
       "      <td>107.129</td>\n",
       "      <td>120.540</td>\n",
       "      <td>134.986</td>\n",
       "      <td>150.412</td>\n",
       "      <td>152.763</td>\n",
       "      <td>136.130</td>\n",
       "      <td>121.033</td>\n",
       "      <td>80.621</td>\n",
       "      <td>43.428</td>\n",
       "      <td>...</td>\n",
       "      <td>83.893958</td>\n",
       "      <td>84.131655</td>\n",
       "      <td>83.241833</td>\n",
       "      <td>83.355714</td>\n",
       "      <td>82.505417</td>\n",
       "      <td>82.612111</td>\n",
       "      <td>81.860500</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>96.193</td>\n",
       "      <td>81.920</td>\n",
       "      <td>107.129</td>\n",
       "      <td>120.540</td>\n",
       "      <td>134.986</td>\n",
       "      <td>150.412</td>\n",
       "      <td>152.763</td>\n",
       "      <td>136.130</td>\n",
       "      <td>121.033</td>\n",
       "      <td>80.621</td>\n",
       "      <td>...</td>\n",
       "      <td>84.539375</td>\n",
       "      <td>84.841667</td>\n",
       "      <td>83.893958</td>\n",
       "      <td>84.131655</td>\n",
       "      <td>83.241833</td>\n",
       "      <td>83.355714</td>\n",
       "      <td>82.505417</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>94.536</td>\n",
       "      <td>96.193</td>\n",
       "      <td>81.920</td>\n",
       "      <td>107.129</td>\n",
       "      <td>120.540</td>\n",
       "      <td>134.986</td>\n",
       "      <td>150.412</td>\n",
       "      <td>152.763</td>\n",
       "      <td>136.130</td>\n",
       "      <td>121.033</td>\n",
       "      <td>...</td>\n",
       "      <td>84.552333</td>\n",
       "      <td>85.716806</td>\n",
       "      <td>84.539375</td>\n",
       "      <td>84.841667</td>\n",
       "      <td>83.893958</td>\n",
       "      <td>84.131655</td>\n",
       "      <td>83.241833</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lag48    lag49    lag50    lag51    lag52    lag53    lag54    lag55  \\\n",
       "5795  120.540  134.986  150.412  152.763  136.130  121.033   80.621   43.428   \n",
       "5856  107.129  120.540  134.986  150.412  152.763  136.130  121.033   80.621   \n",
       "5917   81.920  107.129  120.540  134.986  150.412  152.763  136.130  121.033   \n",
       "5978   96.193   81.920  107.129  120.540  134.986  150.412  152.763  136.130   \n",
       "6039   94.536   96.193   81.920  107.129  120.540  134.986  150.412  152.763   \n",
       "\n",
       "        lag56    lag57  ...  rolling_mean_lag68_window_size24  \\\n",
       "5795   46.840   43.671  ...                         82.505417   \n",
       "5856   43.428   46.840  ...                         83.241833   \n",
       "5917   80.621   43.428  ...                         83.893958   \n",
       "5978  121.033   80.621  ...                         84.539375   \n",
       "6039  136.130  121.033  ...                         84.552333   \n",
       "\n",
       "      expanding_mean_lag69  rolling_mean_lag69_window_size24  \\\n",
       "5795             82.612111                         81.860500   \n",
       "5856             83.355714                         82.505417   \n",
       "5917             84.131655                         83.241833   \n",
       "5978             84.841667                         83.893958   \n",
       "6039             85.716806                         84.539375   \n",
       "\n",
       "      expanding_mean_lag70  rolling_mean_lag70_window_size24  \\\n",
       "5795             81.756654                         81.308000   \n",
       "5856             82.612111                         81.860500   \n",
       "5917             83.355714                         82.505417   \n",
       "5978             84.131655                         83.241833   \n",
       "6039             84.841667                         83.893958   \n",
       "\n",
       "      expanding_mean_lag71  rolling_mean_lag71_window_size24  month  \\\n",
       "5795             81.145600                         80.502083      9   \n",
       "5856             81.756654                         81.308000      9   \n",
       "5917             82.612111                         81.860500      9   \n",
       "5978             83.355714                         82.505417      9   \n",
       "6039             84.131655                         83.241833      9   \n",
       "\n",
       "      dayofweek  hour  \n",
       "5795          5    23  \n",
       "5856          6     0  \n",
       "5917          6     1  \n",
       "5978          6     2  \n",
       "6039          6     3  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = preprocessing(df_train)\n",
    "print(f\"X_train shape : {X_train.shape}\")\n",
    "print(f\"y_train shape : {y_train.shape}\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape : (84735, 99)\n",
      "y_test shape : (84735,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/mlforecast/core.py:455: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feat_name] = feat_vals[restore_idxs]\n",
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/mlforecast/core.py:455: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feat_name] = feat_vals[restore_idxs]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag48</th>\n",
       "      <th>lag49</th>\n",
       "      <th>lag50</th>\n",
       "      <th>lag51</th>\n",
       "      <th>lag52</th>\n",
       "      <th>lag53</th>\n",
       "      <th>lag54</th>\n",
       "      <th>lag55</th>\n",
       "      <th>lag56</th>\n",
       "      <th>lag57</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_lag68_window_size24</th>\n",
       "      <th>expanding_mean_lag69</th>\n",
       "      <th>rolling_mean_lag69_window_size24</th>\n",
       "      <th>expanding_mean_lag70</th>\n",
       "      <th>rolling_mean_lag70_window_size24</th>\n",
       "      <th>expanding_mean_lag71</th>\n",
       "      <th>rolling_mean_lag71_window_size24</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920263</th>\n",
       "      <td>1057.285</td>\n",
       "      <td>1107.518</td>\n",
       "      <td>1177.874</td>\n",
       "      <td>1114.973</td>\n",
       "      <td>860.687</td>\n",
       "      <td>624.847</td>\n",
       "      <td>382.365</td>\n",
       "      <td>246.753</td>\n",
       "      <td>193.661</td>\n",
       "      <td>160.944</td>\n",
       "      <td>...</td>\n",
       "      <td>722.741458</td>\n",
       "      <td>747.325111</td>\n",
       "      <td>723.395542</td>\n",
       "      <td>740.683269</td>\n",
       "      <td>723.535208</td>\n",
       "      <td>734.978880</td>\n",
       "      <td>725.296292</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920328</th>\n",
       "      <td>1055.621</td>\n",
       "      <td>1057.285</td>\n",
       "      <td>1107.518</td>\n",
       "      <td>1177.874</td>\n",
       "      <td>1114.973</td>\n",
       "      <td>860.687</td>\n",
       "      <td>624.847</td>\n",
       "      <td>382.365</td>\n",
       "      <td>246.753</td>\n",
       "      <td>193.661</td>\n",
       "      <td>...</td>\n",
       "      <td>723.696750</td>\n",
       "      <td>753.981429</td>\n",
       "      <td>722.741458</td>\n",
       "      <td>747.325111</td>\n",
       "      <td>723.395542</td>\n",
       "      <td>740.683269</td>\n",
       "      <td>723.535208</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920393</th>\n",
       "      <td>999.628</td>\n",
       "      <td>1055.621</td>\n",
       "      <td>1057.285</td>\n",
       "      <td>1107.518</td>\n",
       "      <td>1177.874</td>\n",
       "      <td>1114.973</td>\n",
       "      <td>860.687</td>\n",
       "      <td>624.847</td>\n",
       "      <td>382.365</td>\n",
       "      <td>246.753</td>\n",
       "      <td>...</td>\n",
       "      <td>724.803458</td>\n",
       "      <td>761.656966</td>\n",
       "      <td>723.696750</td>\n",
       "      <td>753.981429</td>\n",
       "      <td>722.741458</td>\n",
       "      <td>747.325111</td>\n",
       "      <td>723.395542</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920458</th>\n",
       "      <td>1001.917</td>\n",
       "      <td>999.628</td>\n",
       "      <td>1055.621</td>\n",
       "      <td>1057.285</td>\n",
       "      <td>1107.518</td>\n",
       "      <td>1177.874</td>\n",
       "      <td>1114.973</td>\n",
       "      <td>860.687</td>\n",
       "      <td>624.847</td>\n",
       "      <td>382.365</td>\n",
       "      <td>...</td>\n",
       "      <td>726.249667</td>\n",
       "      <td>769.130867</td>\n",
       "      <td>724.803458</td>\n",
       "      <td>761.656966</td>\n",
       "      <td>723.696750</td>\n",
       "      <td>753.981429</td>\n",
       "      <td>722.741458</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920523</th>\n",
       "      <td>1014.902</td>\n",
       "      <td>1001.917</td>\n",
       "      <td>999.628</td>\n",
       "      <td>1055.621</td>\n",
       "      <td>1057.285</td>\n",
       "      <td>1107.518</td>\n",
       "      <td>1177.874</td>\n",
       "      <td>1114.973</td>\n",
       "      <td>860.687</td>\n",
       "      <td>624.847</td>\n",
       "      <td>...</td>\n",
       "      <td>731.313625</td>\n",
       "      <td>778.516258</td>\n",
       "      <td>726.249667</td>\n",
       "      <td>769.130867</td>\n",
       "      <td>724.803458</td>\n",
       "      <td>761.656966</td>\n",
       "      <td>723.696750</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lag48     lag49     lag50     lag51     lag52     lag53     lag54  \\\n",
       "920263  1057.285  1107.518  1177.874  1114.973   860.687   624.847   382.365   \n",
       "920328  1055.621  1057.285  1107.518  1177.874  1114.973   860.687   624.847   \n",
       "920393   999.628  1055.621  1057.285  1107.518  1177.874  1114.973   860.687   \n",
       "920458  1001.917   999.628  1055.621  1057.285  1107.518  1177.874  1114.973   \n",
       "920523  1014.902  1001.917   999.628  1055.621  1057.285  1107.518  1177.874   \n",
       "\n",
       "           lag55    lag56    lag57  ...  rolling_mean_lag68_window_size24  \\\n",
       "920263   246.753  193.661  160.944  ...                        722.741458   \n",
       "920328   382.365  246.753  193.661  ...                        723.696750   \n",
       "920393   624.847  382.365  246.753  ...                        724.803458   \n",
       "920458   860.687  624.847  382.365  ...                        726.249667   \n",
       "920523  1114.973  860.687  624.847  ...                        731.313625   \n",
       "\n",
       "        expanding_mean_lag69  rolling_mean_lag69_window_size24  \\\n",
       "920263            747.325111                        723.395542   \n",
       "920328            753.981429                        722.741458   \n",
       "920393            761.656966                        723.696750   \n",
       "920458            769.130867                        724.803458   \n",
       "920523            778.516258                        726.249667   \n",
       "\n",
       "        expanding_mean_lag70  rolling_mean_lag70_window_size24  \\\n",
       "920263            740.683269                        723.535208   \n",
       "920328            747.325111                        723.395542   \n",
       "920393            753.981429                        722.741458   \n",
       "920458            761.656966                        723.696750   \n",
       "920523            769.130867                        724.803458   \n",
       "\n",
       "        expanding_mean_lag71  rolling_mean_lag71_window_size24  month  \\\n",
       "920263            734.978880                        725.296292      4   \n",
       "920328            740.683269                        723.535208      4   \n",
       "920393            747.325111                        723.395542      4   \n",
       "920458            753.981429                        722.741458      4   \n",
       "920523            761.656966                        723.696750      4   \n",
       "\n",
       "        dayofweek  hour  \n",
       "920263          2    23  \n",
       "920328          3     0  \n",
       "920393          3     1  \n",
       "920458          3     2  \n",
       "920523          3     3  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = preprocessing(df_test)\n",
    "print(f\"X_test shape : {X_test.shape}\")\n",
    "print(f\"y_test shape : {y_test.shape}\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a vanilla LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 24524\n",
      "[LightGBM] [Info] Number of data points in the train set: 854079, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score 485.532565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_mae': np.float64(66.30995098429447),\n",
       " 'test_mae': np.float64(91.88798810682138),\n",
       " 'training_duration': 5.6921632289886475}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(random_state=random_state)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# metrics\n",
    "y_fit = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "train_mae = mean_absolute_error(y_train, y_fit)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "training_duration = end - start\n",
    "metrics = {\"train_mae\": train_mae, \"test_mae\": test_mae, \"training_duration\": training_duration}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the MLFlow experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a terminal, run:\n",
    "```\n",
    "mlflow server --host 127.0.0.1 --port 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/847028692385838956', creation_time=1737798748143, experiment_id='847028692385838956', last_update_time=1737798748143, lifecycle_stage='active', name='Enefit lightgbm Preprocessing 2', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the current active MLflow experiment\n",
    "experiment_name = f\"Enefit {model_name} Preprocessing {preprocessing_version}\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for experiment 'Enefit lightgbm Preprocessing 2': 847028692385838956\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(f\"ID for experiment '{experiment_name}': {experiment.experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log the study's best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study name : lightgbm_preprocessing2_config1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-25 14:28:51,931] Using an existing study with name 'lightgbm_preprocessing2_config1' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "study_name = (\n",
    "    f\"{model_name}_preprocessing{preprocessing_version}_config{config_version}\"\n",
    ")\n",
    "storage_path = \"sqlite:///{}/{}.db\".format(study_path, study_name)\n",
    "print(f\"Study name : {study_name}\")\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_path, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.592949529294766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.592949529294766\n",
      "[LightGBM] [Warning] num_iterations is set=10, num_trees=10 will be ignored. Current value: num_iterations=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.592949529294766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.592949529294766\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 24524\n",
      "[LightGBM] [Info] Number of data points in the train set: 854079, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score 485.532565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.592949529294766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.592949529294766\n",
      "[LightGBM] [Warning] feature_fraction is set=0.592949529294766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.592949529294766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/Documents/Git/End-to-end MLOps for Time Series/.venv/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.592949529294766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.592949529294766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae158aad296042e482ed48b1bfa8da5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/25 14:29:01 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run best_model_lightgbm_preprocessing2_config1_20250125T102851UTC at: http://127.0.0.1:5000/#/experiments/847028692385838956/runs/abc16b1ed5ea4721920091e379d81db6.\n",
      "2025/01/25 14:29:01 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/847028692385838956.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.592949529294766, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.592949529294766\n"
     ]
    }
   ],
   "source": [
    "# run metadata\n",
    "utc_datetime = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SUTC\")\n",
    "run_name = f\"best_model_{study_name}_{utc_datetime}\"\n",
    "\n",
    "# training\n",
    "params = study.best_params\n",
    "model = LGBMRegressor(**params, random_state=random_state)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# metrics\n",
    "y_fit = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "train_mae = mean_absolute_error(y_train, y_fit)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "training_duration = end - start\n",
    "metrics = {\"train_mae\": train_mae, \"test_mae\": test_mae, \"training_duration\": training_duration}\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.lightgbm.log_model(\n",
    "        lgb_model=model, input_example=X_train.iloc[:1], artifact_path=model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
